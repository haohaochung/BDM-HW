{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get data body in spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Paxar Corp said it has acquired Thermo-Print GmbH of Lohn, West Germany, a distributor of Paxar products, for undisclosed terms. Reuter &#3;',\n",
       " 'Shr 10 cts vs 32 cts Net 975,000 vs 3,145,000 Sales 159.1 mln vs 147.3 mln Reuter &#3;',\n",
       " 'Key Tronic corp said it has received contracts to provide seven original equipment manufacturers with which it has not done business recently with over 300,000 computer keyboards for delivery within the next 12 months. The company said \"The new contracts represent an annual increase of approximately 25 pct in unit volume over last year.\" Reuter &#3;']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "data = sc.wholeTextFiles('data/reut2-*')\n",
    "newsArticles = data.map(lambda x:x[1]).flatMap(lambda x:x.split('<BODY>')[1:]).map(lambda x:x.split('</BODY>')[0])\\\n",
    "                   .map(lambda x:re.sub(' +', ' ', x.replace('\\n', ' ')))\n",
    "\n",
    "newsArticles.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Given the Reuters-21578 dataset, please calculate all k-shingles and output the set representation of the text dataset as a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pax', 'r C', 'Cor', 'rp ', 'p s']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 3\n",
    "shingles = newsArticles.flatMap(lambda x:[x[i:i+k] for i in range(len(x)-k+1)]).distinct()\n",
    "\n",
    "shingles.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35077 different shingles.\n",
      "19043 different articles.\n"
     ]
    }
   ],
   "source": [
    "shingles_count = shingles.count()\n",
    "articles_count = newsArticles.count()\n",
    "print(shingles_count, 'different shingles.')\n",
    "print(articles_count, 'different articles.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsArticles = newsArticles.collect()\n",
    "kShinglesMatrix = shingles.map(lambda s:[1 if s in a else 0 for a in newsArticles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kShinglesMatrix.coalesce(1).saveAsTextFile('tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv tmp/part-00000 result/kShinglesMatrix.txt\n",
    "!rm -rf tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Given the set representation, compute the minhash signatures of all documents using MapReduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biggerThanNFirstPrime(N):\n",
    "    p = 2\n",
    "    while True:\n",
    "        isPrime = True\n",
    "        for i in range(2,p//2+1):\n",
    "            if(p%i==0):\n",
    "                isPrime = False\n",
    "                break\n",
    "        if isPrime and p > N:\n",
    "            return p\n",
    "        else:\n",
    "            p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "h = 100\n",
    "a = [random.randint(0, 100) for i in range(h)]\n",
    "b = [random.randint(0, 100) for i in range(h)]\n",
    "p = biggerThanNFirstPrime(articles_count)\n",
    "N = articles_count\n",
    "\n",
    "def rowHash(row, a, b, p, N):\n",
    "    return ((a*row+b)%p)%N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "minHashSignatures = list()\n",
    "kShinglesMatrixZipWithIndex = kShinglesMatrix.zipWithIndex().cache()\n",
    "for i in range(h):\n",
    "    minHashSignatures.append(kShinglesMatrixZipWithIndex\\\n",
    "                             .map(lambda x:[rowHash(x[1], a[i], b[i], p ,N) if c == 1 else (articles_count + 10) for c in x[0]])\\\n",
    "                             .reduce(lambda x, y:[Mx if Mx < My else My for Mx, My in zip(x, y)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result/minHashSignatures.txt', 'w') as result:\n",
    "    for row in minHashSignatures:\n",
    "        result.write(str(row) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from operator import add\n",
    "# bands = 20\n",
    "# r = 5\n",
    "# similarRate = 0.8\n",
    "# buckets = articles_count\n",
    "# hashFuct = [[random.randint(0, 100) for i in range(r + 1)] for j in range(bands)]\n",
    "\n",
    "# for i in range(articles_count):\n",
    "#     candidatePairs = sc.emptyRDD()\n",
    "#     for j in range(bands):\n",
    "#         band = sc.parallelize(np.array(minHashSignatures[j*r:j*r+r]).T)\\\n",
    "#                  .zipWithIndex().filter(lambda x:x[1] >= i)\\\n",
    "#                  .map(lambda x:(x[1], (np.array(x[0]).dot(np.array(hashFuct[j][:r])) + hashFuct[j][-1]) % buckets))\\\n",
    "#                  .cache()\n",
    "#         bucket = band.first()[1]\n",
    "#         candidatePairs = candidatePairs.union(band.filter(lambda x:x[0] > i and x[1] == bucket).map(lambda x:((i, x[0]), 1)))\n",
    "#     candidatePairs = candidatePairs.reduceByKey(add).filter(lambda x:x[1] >= bands*similarRate)\n",
    "#     print(candidatePairs.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from operator import add\n",
    "bands = 20\n",
    "r = 5\n",
    "similarRate = 0.8\n",
    "buckets = articles_count\n",
    "hashFuct = [[random.randint(0, 100) for i in range(r + 1)] for j in range(bands)]\n",
    "\n",
    "with open('result/candidatePairs.txt', 'w') as result:\n",
    "    for i in range(articles_count):\n",
    "        candidatePairs = list()\n",
    "        for j in range(bands):\n",
    "            band = np.array(minHashSignatures[j*r:j*r+r]).T\n",
    "            band = [(np.array(article).dot(np.array(hashFuct[j][:r])) + hashFuct[j][-1]) % buckets for article in band]\n",
    "            for k, article in enumerate(band):\n",
    "                if k > i and article == band[i]:\n",
    "                    candidatePairs.append(k)\n",
    "        candidatePairs = [(article, candidatePairs.count(article)) for article in set(candidatePairs)]\n",
    "        candidatePairsTreshold = list()\n",
    "        for candidatePair in candidatePairs:\n",
    "            if candidatePair[1] >= bands*similarRate:\n",
    "                candidatePairsTreshold.append(candidatePair[0])\n",
    "        result.write('Articles' + str(i) + ':' + str(candidatePairsTreshold) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
